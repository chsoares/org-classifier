# Organization Classifier


## ğŸ¯ Funcionalidades

- **Processamento de dados Excel**: Carrega e unifica dados de mÃºltiplas abas da COP29
- **NormalizaÃ§Ã£o de organizaÃ§Ãµes**: Agrupa nomes similares usando fuzzy matching
- **Web scraping inteligente**: Busca e extrai conteÃºdo de sites organizacionais
- **ClassificaÃ§Ã£o por IA**: Identifica organizaÃ§Ãµes do setor de seguros usando OpenRouter
- **Interface web**: Dashboard Streamlit para visualizaÃ§Ã£o e correÃ§Ã£o manual
- **Sistema de cache**: Evita reprocessamento desnecessÃ¡rio
- **Tracking detalhado**: Acompanha cada etapa do processo para debugging

## ğŸš€ Como Usar

### 1. ConfiguraÃ§Ã£o do Ambiente

```bash
# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. ConfiguraÃ§Ã£o

```bash
# Criar arquivo .env com sua API key do OpenRouter
echo "OPENROUTER_API_KEY=sua_chave_aqui" > .env
```

### 3. Preparar Dados

Coloque o arquivo `COP29_FLOP_On-site.xlsx` na pasta `data/raw/`

### 4. Executar

```bash
# Verificar configuraÃ§Ã£o
python main.py

# Teste com dataset pequeno
python main.py --test

# Processamento completo (pode demorar horas)
python run_full_dataset.py

# Interface web
python run_streamlit.py
```

## ğŸ“Š Resultados

- `data/results/organizations.csv` - Lista de organizaÃ§Ãµes com classificaÃ§Ãµes
- `data/results/people.csv` - Participantes com informaÃ§Ãµes de seguradoras
- `data/cache/` - Cache de resultados para evitar reprocessamento

## ğŸ—ï¸ Arquitetura

```
src/
â”œâ”€â”€ core/           # Processamento de dados e cache
â”œâ”€â”€ scraping/       # Web scraping e busca
â”œâ”€â”€ classification/ # ClassificaÃ§Ã£o por IA
â”œâ”€â”€ pipeline/       # Pipeline principal
â”œâ”€â”€ utils/          # UtilitÃ¡rios e configuraÃ§Ã£o
â””â”€â”€ ui/            # Interface Streamlit
```

## ğŸ“ˆ Pipeline de Processamento

1. **Carregamento**: LÃª arquivo Excel e extrai dados relevantes
2. **NormalizaÃ§Ã£o**: Agrupa organizaÃ§Ãµes com nomes similares
3. **Web Search**: Busca sites oficiais das organizaÃ§Ãµes
4. **Scraping**: Extrai conteÃºdo relevante dos sites
5. **ClassificaÃ§Ã£o**: Usa IA para identificar seguradoras
6. **Merge**: Combina resultados com dataset original

## ğŸ› ï¸ Tecnologias

- **Python 3.13+**
- **pandas**: Processamento de dados
- **requests + BeautifulSoup**: Web scraping
- **rapidfuzz**: Fuzzy string matching
- **OpenRouter API**: ClassificaÃ§Ã£o por IA
- **Streamlit**: Interface web
- **plotly**: VisualizaÃ§Ãµes

## ğŸ“‹ Status do Projeto - v1.0 âœ…

- [x] **ConfiguraÃ§Ã£o inicial e logging**
- [x] **Carregamento e processamento de dados Excel**
- [x] **NormalizaÃ§Ã£o de nomes de organizaÃ§Ãµes**
- [x] **Sistema de tracking de organizaÃ§Ãµes**
- [x] **Web scraping de sites organizacionais**
- [x] **ClassificaÃ§Ã£o por IA**
- [x] **Interface Streamlit**
- [x] **Sistema de cache**
- [x] **Processamento em lote**
- [x] **Merge de resultados**
- [x] **ValidaÃ§Ã£o e testes**

## ğŸ‰ VersÃ£o 1.0 Completa

O sistema estÃ¡ totalmente funcional e foi testado com sucesso no dataset completo da COP29. Todas as funcionalidades principais foram implementadas e validadas.
