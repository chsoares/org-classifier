#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Cache Manager - Sistema de cache para resultados de processamento

Este m√≥dulo √© respons√°vel por:
1. Salvar resultados de processamento para evitar reprocessamento
2. Verificar se organiza√ß√µes j√° foram processadas
3. Permitir limpeza manual do cache
4. Incluir timestamps para controle de validade
5. Organizar cache por tipo (busca, extra√ß√£o, classifica√ß√£o)

√â como ter uma "mem√≥ria" do sistema que lembra o que j√° foi feito!
"""

import json
import os
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import sys

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.logger_config import setup_logger


class CacheManager:
    """
    Gerenciador de cache para resultados de processamento
    
    Organiza o cache em diferentes tipos:
    - web_search: URLs encontradas para organiza√ß√µes
    - content_extraction: Conte√∫do extra√≠do dos websites
    - classification: Resultados de classifica√ß√£o IA
    - full_results: Resultados completos do pipeline
    """
    
    def __init__(self, cache_dir: str = "data/cache"):
        """
        Inicializa o gerenciador de cache
        
        Args:
            cache_dir: Diret√≥rio base para armazenar cache
        """
        self.logger, _ = setup_logger("cache_manager", log_to_file=True)
        
        self.cache_dir = Path(cache_dir)
        
        # Criar estrutura de diret√≥rios
        self.cache_types = {
            'web_search': self.cache_dir / 'web_search',
            'content_extraction': self.cache_dir / 'content_extraction', 
            'classification': self.cache_dir / 'classification',
            'full_results': self.cache_dir / 'full_results'
        }
        
        # Criar diret√≥rios se n√£o existirem
        for cache_type, path in self.cache_types.items():
            path.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"üíæ Cache Manager inicializado: {self.cache_dir}")
        self.logger.debug(f"Tipos de cache: {list(self.cache_types.keys())}")
    
    def _generate_cache_key(self, org_name: str) -> str:
        """
        Gera uma chave √∫nica para a organiza√ß√£o
        
        Usa hash MD5 do nome normalizado para evitar problemas com:
        - Caracteres especiais
        - Nomes muito longos
        - Case sensitivity
        
        Args:
            org_name: Nome da organiza√ß√£o
            
        Returns:
            Chave √∫nica para cache
        """
        # Normalizar nome (lowercase, sem espa√ßos extras)
        normalized_name = org_name.lower().strip()
        
        # Gerar hash MD5
        hash_object = hashlib.md5(normalized_name.encode())
        cache_key = hash_object.hexdigest()
        
        self.logger.debug(f"Cache key para '{org_name}': {cache_key}")
        return cache_key
    
    def _get_cache_file_path(self, cache_type: str, org_name: str) -> Path:
        """
        Gera o caminho completo do arquivo de cache
        
        Args:
            cache_type: Tipo de cache (web_search, content_extraction, etc.)
            org_name: Nome da organiza√ß√£o
            
        Returns:
            Caminho para o arquivo de cache
        """
        if cache_type not in self.cache_types:
            raise ValueError(f"Tipo de cache inv√°lido: {cache_type}")
        
        cache_key = self._generate_cache_key(org_name)
        return self.cache_types[cache_type] / f"{cache_key}.json"
    
    def save_to_cache(self, cache_type: str, org_name: str, data: Dict[str, Any]) -> bool:
        """
        Salva dados no cache
        
        Args:
            cache_type: Tipo de cache
            org_name: Nome da organiza√ß√£o
            data: Dados para salvar
            
        Returns:
            True se salvou com sucesso
        """
        try:
            cache_file = self._get_cache_file_path(cache_type, org_name)
            
            # Adicionar metadados e converter datetime para string
            cache_data = {
                'organization_name': org_name,
                'cache_type': cache_type,
                'timestamp': datetime.now().isoformat(),
                'data': self._serialize_data(data)
            }
            
            # Salvar arquivo JSON
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, indent=2, ensure_ascii=False)
            
            self.logger.debug(f"üíæ Cache salvo: {cache_type} para {org_name}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao salvar cache {cache_type} para {org_name}: {str(e)}")
            return False
    
    def load_from_cache(self, cache_type: str, org_name: str) -> Optional[Dict[str, Any]]:
        """
        Carrega dados do cache
        
        Args:
            cache_type: Tipo de cache
            org_name: Nome da organiza√ß√£o
            
        Returns:
            Dados do cache ou None se n√£o encontrado
        """
        try:
            cache_file = self._get_cache_file_path(cache_type, org_name)
            
            if not cache_file.exists():
                self.logger.debug(f"üì≠ Cache n√£o encontrado: {cache_type} para {org_name}")
                return None
            
            # Carregar arquivo JSON
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            self.logger.debug(f"üì¶ Cache carregado: {cache_type} para {org_name}")
            return cache_data['data']
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao carregar cache {cache_type} para {org_name}: {str(e)}")
            return None
    
    def is_cached(self, cache_type: str, org_name: str) -> bool:
        """
        Verifica se uma organiza√ß√£o est√° no cache
        
        Args:
            cache_type: Tipo de cache
            org_name: Nome da organiza√ß√£o
            
        Returns:
            True se est√° no cache
        """
        cache_file = self._get_cache_file_path(cache_type, org_name)
        return cache_file.exists()
    
    def get_cache_info(self, cache_type: str, org_name: str) -> Optional[Dict[str, Any]]:
        """
        Obt√©m informa√ß√µes sobre um item do cache (sem carregar os dados)
        
        Args:
            cache_type: Tipo de cache
            org_name: Nome da organiza√ß√£o
            
        Returns:
            Metadados do cache ou None
        """
        try:
            cache_file = self._get_cache_file_path(cache_type, org_name)
            
            if not cache_file.exists():
                return None
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            return {
                'organization_name': cache_data.get('organization_name'),
                'cache_type': cache_data.get('cache_type'),
                'timestamp': cache_data.get('timestamp'),
                'file_size': cache_file.stat().st_size
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao obter info do cache: {str(e)}")
            return None
    
    def clear_cache(self, cache_type: Optional[str] = None, org_name: Optional[str] = None) -> int:
        """
        Limpa cache
        
        Args:
            cache_type: Tipo espec√≠fico para limpar (None = todos)
            org_name: Organiza√ß√£o espec√≠fica (None = todas)
            
        Returns:
            N√∫mero de arquivos removidos
        """
        removed_count = 0
        
        try:
            if cache_type is not None and org_name is not None:
                # Limpar cache espec√≠fico de uma organiza√ß√£o
                cache_file = self._get_cache_file_path(cache_type, org_name)
                if cache_file.exists():
                    cache_file.unlink()
                    removed_count = 1
                    self.logger.info(f"üóëÔ∏è Cache removido: {cache_type} para {org_name}")
            
            elif cache_type is not None:
                # Limpar todos os caches de um tipo
                cache_dir = self.cache_types[cache_type]
                for cache_file in cache_dir.glob("*.json"):
                    cache_file.unlink()
                    removed_count += 1
                self.logger.info(f"üóëÔ∏è Cache tipo {cache_type} limpo: {removed_count} arquivos")
            
            elif org_name is not None:
                # Limpar todos os tipos de cache para uma organiza√ß√£o espec√≠fica
                for cache_type_name, cache_dir in self.cache_types.items():
                    cache_file = self._get_cache_file_path(cache_type_name, org_name)
                    if cache_file.exists():
                        cache_file.unlink()
                        removed_count += 1
                        self.logger.debug(f"üóëÔ∏è Cache removido: {cache_type_name} para {org_name}")
                self.logger.info(f"üóëÔ∏è Todos os caches removidos para {org_name}: {removed_count} arquivos")
            
            else:
                # Limpar todo o cache
                for cache_dir in self.cache_types.values():
                    for cache_file in cache_dir.glob("*.json"):
                        cache_file.unlink()
                        removed_count += 1
                self.logger.info(f"üóëÔ∏è Todo cache limpo: {removed_count} arquivos")
        
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao limpar cache: {str(e)}")
        
        return removed_count
    
    def get_cache_statistics(self) -> Dict[str, Any]:
        """
        Obt√©m estat√≠sticas do cache
        
        Returns:
            Dicion√°rio com estat√≠sticas
        """
        stats = {
            'total_files': 0,
            'total_size_bytes': 0,
            'by_type': {}
        }
        
        try:
            for cache_type, cache_dir in self.cache_types.items():
                type_files = list(cache_dir.glob("*.json"))
                type_count = len(type_files)
                type_size = sum(f.stat().st_size for f in type_files)
                
                stats['by_type'][cache_type] = {
                    'files': type_count,
                    'size_bytes': type_size
                }
                
                stats['total_files'] += type_count
                stats['total_size_bytes'] += type_size
            
            # Converter bytes para MB
            stats['total_size_mb'] = stats['total_size_bytes'] / (1024 * 1024)
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao calcular estat√≠sticas: {str(e)}")
        
        return stats
    
    def list_cached_organizations(self, cache_type: Optional[str] = None) -> List[str]:
        """
        Lista organiza√ß√µes que est√£o no cache
        
        Args:
            cache_type: Tipo espec√≠fico (None = todos os tipos)
            
        Returns:
            Lista de nomes de organiza√ß√µes
        """
        organizations = set()
        
        try:
            cache_types_to_check = [cache_type] if cache_type else list(self.cache_types.keys())
            
            for ct in cache_types_to_check:
                cache_dir = self.cache_types[ct]
                
                for cache_file in cache_dir.glob("*.json"):
                    try:
                        with open(cache_file, 'r', encoding='utf-8') as f:
                            cache_data = json.load(f)
                            org_name = cache_data.get('organization_name')
                            if org_name:
                                organizations.add(org_name)
                    except Exception:
                        continue  # Pular arquivos corrompidos
        
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao listar organiza√ß√µes: {str(e)}")
        
        return sorted(list(organizations))
    
    def _serialize_data(self, data: Any) -> Any:
        """
        Converte objetos datetime para strings para serializa√ß√£o JSON
        
        Args:
            data: Dados para serializar
            
        Returns:
            Dados serializ√°veis
        """
        if isinstance(data, dict):
            return {key: self._serialize_data(value) for key, value in data.items()}
        elif isinstance(data, list):
            return [self._serialize_data(item) for item in data]
        elif isinstance(data, datetime):
            return data.isoformat()
        else:
            return data


def main():
    """Fun√ß√£o para testar o cache manager"""
    cache_manager = CacheManager()
    
    print("üß™ Testando Cache Manager")
    print("=" * 40)
    
    # Testar salvamento
    test_data = {
        'website_url': 'https://www.allianz.com',
        'search_method': 'wikipedia',
        'timestamp': datetime.now().isoformat()
    }
    
    print("üíæ Salvando dados de teste...")
    success = cache_manager.save_to_cache('web_search', 'Allianz SE', test_data)
    print(f"Resultado: {'‚úÖ Sucesso' if success else '‚ùå Falha'}")
    
    # Testar carregamento
    print("\nüì¶ Carregando dados do cache...")
    loaded_data = cache_manager.load_from_cache('web_search', 'Allianz SE')
    if loaded_data:
        print("‚úÖ Dados carregados:")
        print(f"  URL: {loaded_data.get('website_url')}")
        print(f"  M√©todo: {loaded_data.get('search_method')}")
    else:
        print("‚ùå Dados n√£o encontrados")
    
    # Testar estat√≠sticas
    print("\nüìä Estat√≠sticas do cache:")
    stats = cache_manager.get_cache_statistics()
    print(f"  Total de arquivos: {stats['total_files']}")
    print(f"  Tamanho total: {stats['total_size_mb']:.2f} MB")
    
    # Listar organiza√ß√µes
    print("\nüìã Organiza√ß√µes no cache:")
    orgs = cache_manager.list_cached_organizations()
    for org in orgs:
        print(f"  ‚Ä¢ {org}")


if __name__ == "__main__":
    main()