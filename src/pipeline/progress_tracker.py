#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Progress Tracker - Sistema de tracking do progresso de classificaÃ§Ã£o de organizaÃ§Ãµes

Este mÃ³dulo Ã© responsÃ¡vel por:
1. Criar DataFrame de tracking para organizaÃ§Ãµes Ãºnicas
2. Acompanhar cada etapa do processo (website, scraping, classificaÃ§Ã£o)
3. Registrar erros e timestamps
4. Gerar relatÃ³rios de progresso
"""

import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Any
import sys
from datetime import datetime
import json

# Adicionar src ao path para imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.logger_config import setup_logger
from utils.config_manager import config_manager


class ProgressTracker:
    """
    Sistema de tracking do progresso de classificaÃ§Ã£o de organizaÃ§Ãµes
    """
    
    def __init__(self):
        self.logger, _ = setup_logger("progress_tracker", log_to_file=True)
        
        self.logger.info("ğŸ“Š Inicializando Progress Tracker")
        
        # Caminhos dos arquivos
        self.tracking_file = Path("data/processed/organizations_tracking.csv")
        self.progress_file = Path("data/processed/progress_report.json")
    
    def create_tracking_dataframe(self, org_list: List[str]) -> pd.DataFrame:
        """
        Cria DataFrame de tracking para lista de organizaÃ§Ãµes
        
        Args:
            org_list: Lista de nomes de organizaÃ§Ãµes Ãºnicas
            
        Returns:
            DataFrame de tracking inicializado
        """
        self.logger.info(f"ğŸ“‹ Criando DataFrame de tracking para {len(org_list)} organizaÃ§Ãµes")
        
        # Estrutura do DataFrame de tracking
        tracking_data = {
            # IdentificaÃ§Ã£o da organizaÃ§Ã£o
            'home_organization': org_list,
            'normalized_name': org_list,  # SerÃ¡ atualizado se houver normalizaÃ§Ã£o
            'occurrence_count': [0] * len(org_list),  # SerÃ¡ preenchido depois
            
            # Etapa 1: Busca de website
            'website_found': [None] * len(org_list),  # bool: True/False/None
            'website_url': [None] * len(org_list),    # str: URL encontrada ou None
            'website_search_method': [None] * len(org_list),  # str: 'google', 'duckduckgo', 'bing', 'failed'
            'website_search_timestamp': [None] * len(org_list),  # datetime
            'website_search_error': [None] * len(org_list),  # str: mensagem de erro
            
            # Etapa 2: Scraping de conteÃºdo
            'scraping_success': [None] * len(org_list),  # bool: True/False/None
            'content_length': [None] * len(org_list),    # int: tamanho do conteÃºdo
            'scraping_timestamp': [None] * len(org_list),  # datetime
            'scraping_error': [None] * len(org_list),    # str: mensagem de erro
            
            # Etapa 3: ClassificaÃ§Ã£o por IA
            'classification_success': [None] * len(org_list),  # bool: True/False/None
            'classification_result': [None] * len(org_list),   # str: 'Yes', 'No', ou None
            'classification_timestamp': [None] * len(org_list),  # datetime
            'classification_error': [None] * len(org_list),     # str: mensagem de erro
            
            # Resultado final
            'is_insurance': [None] * len(org_list),      # bool: True/False/None
            'process_status': ['pending'] * len(org_list),  # str: status do processo
            'processing_duration': [None] * len(org_list),  # float: tempo total em segundos
            'last_updated': [datetime.now()] * len(org_list),  # datetime: Ãºltima atualizaÃ§Ã£o
            
            # Metadados
            'retry_count': [0] * len(org_list),          # int: nÃºmero de tentativas
            'priority': ['normal'] * len(org_list),     # str: 'high', 'normal', 'low'
            'notes': [None] * len(org_list)             # str: observaÃ§Ãµes adicionais
        }
        
        tracking_df = pd.DataFrame(tracking_data)
        
        self.logger.success(f"âœ¨ DataFrame de tracking criado com {len(tracking_df)} organizaÃ§Ãµes")
        self.logger.info(f"ğŸ“Š Colunas de tracking: {len(tracking_df.columns)}")
        
        return tracking_df
    
    def load_or_create_tracking(self, organizations_file: str = "data/processed/organizations_mapping.csv") -> pd.DataFrame:
        """
        Carrega tracking existente ou cria novo baseado no arquivo de organizaÃ§Ãµes
        
        Args:
            organizations_file: Arquivo com mapeamento de organizaÃ§Ãµes
            
        Returns:
            DataFrame de tracking
        """
        self.logger.info("ğŸ”„ Carregando ou criando sistema de tracking...")
        
        # Verificar se jÃ¡ existe tracking
        if self.tracking_file.exists():
            self.logger.info(f"ğŸ“‚ Carregando tracking existente: {self.tracking_file}")
            try:
                tracking_df = pd.read_csv(self.tracking_file)
                
                # Converter colunas de data
                date_columns = ['website_search_timestamp', 'scraping_timestamp', 
                              'classification_timestamp', 'last_updated']
                for col in date_columns:
                    if col in tracking_df.columns:
                        tracking_df[col] = pd.to_datetime(tracking_df[col])
                
                self.logger.success(f"âœ¨ Tracking carregado: {len(tracking_df)} organizaÃ§Ãµes")
                return tracking_df
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ Erro ao carregar tracking existente: {e}")
                self.logger.info("ğŸ”„ Criando novo tracking...")
        
        # Carregar organizaÃ§Ãµes do arquivo de mapeamento
        orgs_path = Path(organizations_file)
        if not orgs_path.exists():
            raise FileNotFoundError(f"Arquivo de organizaÃ§Ãµes nÃ£o encontrado: {orgs_path}")
        
        self.logger.info(f"ğŸ“‚ Carregando organizaÃ§Ãµes de: {orgs_path}")
        orgs_df = pd.read_csv(orgs_path)
        
        # Usar nomes normalizados Ãºnicos
        unique_orgs = orgs_df['normalized_name'].unique().tolist()
        
        # Criar novo tracking
        tracking_df = self.create_tracking_dataframe(unique_orgs)
        
        # Preencher informaÃ§Ãµes das organizaÃ§Ãµes
        org_info = orgs_df.groupby('normalized_name').agg({
            'original_name': 'first',  # Pegar o primeiro nome original
            'occurrence_count': 'sum'  # Somar todas as ocorrÃªncias
        }).reset_index()
        
        # Atualizar tracking com informaÃ§Ãµes das organizaÃ§Ãµes
        tracking_df = tracking_df.merge(
            org_info[['normalized_name', 'occurrence_count']], 
            on='normalized_name', 
            how='left',
            suffixes=('', '_new')
        )
        tracking_df['occurrence_count'] = tracking_df['occurrence_count_new'].fillna(0)
        tracking_df.drop('occurrence_count_new', axis=1, inplace=True)
        
        # Salvar tracking inicial
        self.save_tracking(tracking_df)
        
        return tracking_df
    
    def update_organization_status(self, tracking_df: pd.DataFrame, org_name: str, 
                                 status_data: Dict[str, Any]) -> pd.DataFrame:
        """
        Atualiza status de uma organizaÃ§Ã£o especÃ­fica
        
        Args:
            tracking_df: DataFrame de tracking
            org_name: Nome da organizaÃ§Ã£o
            status_data: DicionÃ¡rio com dados de status
            
        Returns:
            DataFrame atualizado
        """
        # Encontrar Ã­ndice da organizaÃ§Ã£o
        mask = tracking_df['normalized_name'] == org_name
        
        if not mask.any():
            self.logger.warning(f"âš ï¸ OrganizaÃ§Ã£o nÃ£o encontrada no tracking: {org_name}")
            return tracking_df
        
        idx = tracking_df[mask].index[0]
        
        # Atualizar campos fornecidos
        for field, value in status_data.items():
            if field in tracking_df.columns:
                tracking_df.at[idx, field] = value
        
        # Sempre atualizar timestamp
        tracking_df.at[idx, 'last_updated'] = datetime.now()
        
        # Atualizar status do processo baseado no progresso
        current_status = self._determine_process_status(tracking_df.iloc[idx])
        tracking_df.at[idx, 'process_status'] = current_status
        
        self.logger.debug(f"ğŸ“ Status atualizado para '{org_name}': {current_status}")
        
        return tracking_df
    
    def _determine_process_status(self, row: pd.Series) -> str:
        """
        Determina o status do processo baseado no progresso atual
        
        Args:
            row: Linha do DataFrame de tracking
            
        Returns:
            Status do processo
        """
        # Se classificaÃ§Ã£o foi bem-sucedida
        if row['classification_success'] is True:
            return 'completed'
        
        # Se classificaÃ§Ã£o falhou
        if row['classification_success'] is False:
            return 'classification_failed'
        
        # Se scraping falhou
        if row['scraping_success'] is False:
            return 'scraping_failed'
        
        # Se website nÃ£o foi encontrado
        if row['website_found'] is False:
            return 'website_not_found'
        
        # Se website foi encontrado mas scraping ainda nÃ£o foi tentado
        if row['website_found'] is True and row['scraping_success'] is None:
            return 'website_found'
        
        # Se scraping foi bem-sucedido mas classificaÃ§Ã£o ainda nÃ£o foi tentada
        if row['scraping_success'] is True and row['classification_success'] is None:
            return 'content_extracted'
        
        # Status padrÃ£o
        return 'pending'
    
    def get_processing_statistics(self, tracking_df: pd.DataFrame) -> Dict[str, Any]:
        """
        Gera estatÃ­sticas de processamento
        
        Args:
            tracking_df: DataFrame de tracking
            
        Returns:
            DicionÃ¡rio com estatÃ­sticas
        """
        total_orgs = len(tracking_df)
        
        # Contar por status
        status_counts = tracking_df['process_status'].value_counts().to_dict()
        
        # EstatÃ­sticas por etapa
        website_stats = {
            'found': (tracking_df['website_found'] == True).sum(),
            'not_found': (tracking_df['website_found'] == False).sum(),
            'pending': tracking_df['website_found'].isnull().sum()
        }
        
        scraping_stats = {
            'success': (tracking_df['scraping_success'] == True).sum(),
            'failed': (tracking_df['scraping_success'] == False).sum(),
            'pending': tracking_df['scraping_success'].isnull().sum()
        }
        
        classification_stats = {
            'success': (tracking_df['classification_success'] == True).sum(),
            'failed': (tracking_df['classification_success'] == False).sum(),
            'pending': tracking_df['classification_success'].isnull().sum()
        }
        
        # Resultados finais
        insurance_results = {
            'insurance': (tracking_df['is_insurance'] == True).sum(),
            'not_insurance': (tracking_df['is_insurance'] == False).sum(),
            'unknown': tracking_df['is_insurance'].isnull().sum()
        }
        
        # Calcular progresso geral
        completed = status_counts.get('completed', 0)
        progress_percentage = (completed / total_orgs) * 100 if total_orgs > 0 else 0
        
        stats = {
            'timestamp': datetime.now().isoformat(),
            'total_organizations': total_orgs,
            'progress_percentage': round(progress_percentage, 1),
            'status_distribution': status_counts,
            'website_search': website_stats,
            'content_scraping': scraping_stats,
            'classification': classification_stats,
            'final_results': insurance_results,
            'top_errors': self._get_top_errors(tracking_df)
        }
        
        return stats
    
    def _get_top_errors(self, tracking_df: pd.DataFrame, top_n: int = 5) -> Dict[str, int]:
        """
        ObtÃ©m os erros mais comuns
        
        Args:
            tracking_df: DataFrame de tracking
            top_n: NÃºmero de erros principais
            
        Returns:
            DicionÃ¡rio com erros mais comuns
        """
        all_errors = []
        
        # Coletar erros de todas as etapas
        error_columns = ['website_search_error', 'scraping_error', 'classification_error']
        
        for col in error_columns:
            if col in tracking_df.columns:
                errors = tracking_df[col].dropna().tolist()
                all_errors.extend(errors)
        
        if not all_errors:
            return {}
        
        # Contar erros
        error_counts = pd.Series(all_errors).value_counts().head(top_n)
        
        return error_counts.to_dict()
    
    def save_tracking(self, tracking_df: pd.DataFrame) -> None:
        """
        Salva DataFrame de tracking
        
        Args:
            tracking_df: DataFrame de tracking
        """
        try:
            # Criar diretÃ³rio se nÃ£o existir
            self.tracking_file.parent.mkdir(parents=True, exist_ok=True)
            
            # Salvar CSV
            tracking_df.to_csv(self.tracking_file, index=False, encoding='utf-8')
            
            self.logger.debug(f"ğŸ’¾ Tracking salvo: {self.tracking_file}")
            
        except Exception as e:
            self.logger.error(f"âŒ Erro ao salvar tracking: {e}")
            raise
    
    def save_progress_report(self, tracking_df: pd.DataFrame) -> None:
        """
        Salva relatÃ³rio de progresso em JSON
        
        Args:
            tracking_df: DataFrame de tracking
        """
        try:
            stats = self.get_processing_statistics(tracking_df)
            
            # Criar diretÃ³rio se nÃ£o existir
            self.progress_file.parent.mkdir(parents=True, exist_ok=True)
            
            # Salvar JSON
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ğŸ“Š RelatÃ³rio de progresso salvo: {self.progress_file}")
            
        except Exception as e:
            self.logger.error(f"âŒ Erro ao salvar relatÃ³rio: {e}")
            raise
    
    def export_tracking_data(self, tracking_df: pd.DataFrame, file_path: str) -> None:
        """
        Exporta dados de tracking para arquivo especÃ­fico
        
        Args:
            tracking_df: DataFrame de tracking
            file_path: Caminho do arquivo de destino
        """
        try:
            export_path = Path(file_path)
            export_path.parent.mkdir(parents=True, exist_ok=True)
            
            if export_path.suffix.lower() == '.json':
                # Exportar como JSON
                tracking_dict = tracking_df.to_dict('records')
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(tracking_dict, f, indent=2, ensure_ascii=False, default=str)
            else:
                # Exportar como CSV
                tracking_df.to_csv(export_path, index=False, encoding='utf-8')
            
            self.logger.info(f"ğŸ“¤ Dados exportados para: {export_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ Erro ao exportar dados: {e}")
            raise
    
    def generate_summary_report(self, tracking_df: pd.DataFrame) -> str:
        """
        Gera relatÃ³rio resumido em texto
        
        Args:
            tracking_df: DataFrame de tracking
            
        Returns:
            RelatÃ³rio em formato texto
        """
        stats = self.get_processing_statistics(tracking_df)
        
        report = f"""
ğŸ“Š RELATÃ“RIO DE PROGRESSO - ORGANIZATION INSURANCE CLASSIFIER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ• Gerado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}

ğŸ“ˆ PROGRESSO GERAL
â”œâ”€ Total de organizaÃ§Ãµes: {stats['total_organizations']:,}
â”œâ”€ Progresso: {stats['progress_percentage']:.1f}%
â””â”€ ConcluÃ­das: {stats['status_distribution'].get('completed', 0):,}

ğŸ” BUSCA DE WEBSITES
â”œâ”€ Encontrados: {stats['website_search']['found']:,}
â”œâ”€ NÃ£o encontrados: {stats['website_search']['not_found']:,}
â””â”€ Pendentes: {stats['website_search']['pending']:,}

ğŸŒ EXTRAÃ‡ÃƒO DE CONTEÃšDO
â”œâ”€ Sucessos: {stats['content_scraping']['success']:,}
â”œâ”€ Falhas: {stats['content_scraping']['failed']:,}
â””â”€ Pendentes: {stats['content_scraping']['pending']:,}

ğŸ¤– CLASSIFICAÃ‡ÃƒO POR IA
â”œâ”€ Sucessos: {stats['classification']['success']:,}
â”œâ”€ Falhas: {stats['classification']['failed']:,}
â””â”€ Pendentes: {stats['classification']['pending']:,}

ğŸ¢ RESULTADOS FINAIS
â”œâ”€ OrganizaÃ§Ãµes de seguros: {stats['final_results']['insurance']:,}
â”œâ”€ NÃ£o relacionadas a seguros: {stats['final_results']['not_insurance']:,}
â””â”€ NÃ£o classificadas: {stats['final_results']['unknown']:,}

ğŸ“‹ STATUS DETALHADO
"""
        
        for status, count in stats['status_distribution'].items():
            report += f"â”œâ”€ {status.replace('_', ' ').title()}: {count:,}\n"
        
        if stats['top_errors']:
            report += f"\nâŒ PRINCIPAIS ERROS\n"
            for error, count in stats['top_errors'].items():
                report += f"â”œâ”€ {error[:50]}{'...' if len(error) > 50 else ''}: {count}\n"
        
        return report


def main():
    """FunÃ§Ã£o para testar o progress tracker"""
    tracker = ProgressTracker()
    
    try:
        # Carregar ou criar tracking
        tracking_df = tracker.load_or_create_tracking()
        
        print(f"\nğŸ“Š Sistema de tracking inicializado:")
        print(f"OrganizaÃ§Ãµes: {len(tracking_df)}")
        print(f"Colunas: {len(tracking_df.columns)}")
        
        # Gerar estatÃ­sticas
        stats = tracker.get_processing_statistics(tracking_df)
        print(f"\nProgresso atual: {stats['progress_percentage']:.1f}%")
        print(f"Status: {stats['status_distribution']}")
        
        # Salvar relatÃ³rio
        tracker.save_progress_report(tracking_df)
        
        # Gerar relatÃ³rio resumido
        report = tracker.generate_summary_report(tracking_df)
        print(report)
        
    except Exception as e:
        print(f"Erro: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()